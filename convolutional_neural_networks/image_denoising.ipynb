{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f80cd6",
   "metadata": {},
   "source": [
    "# Image Denoising Challenge\n",
    "\n",
    "The goal for this challenge is to leverage your knowledge of Deep Learning to design and train a denoising model. For a given noisy image $X$, our model should learn to predict the denoised image $y$.\n",
    "\n",
    "\n",
    "**Objectives**\n",
    "- Visualize images\n",
    "- Preprocess images for the neural network\n",
    "- Fit a custom CNN for the task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd67a8f",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "üëâ Let's download the dataset archive.\n",
    "It contains RGB and Black & White images we will be using for the rest of this challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d9e72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T13:12:44.663623Z",
     "start_time": "2021-06-17T13:12:35.284111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  1 90.1M    1 1366k    0     0   972k      0  0:01:34  0:00:01  0:01:33  971k"
     ]
    }
   ],
   "source": [
    "! curl https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/paintings.zip > paintings.zip\n",
    "! unzip -nq \"paintings.zip\" \n",
    "! rm \"paintings.zip\"\n",
    "! ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1fe11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b0684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T16:29:50.068129Z",
     "start_time": "2021-06-22T16:29:50.031812Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_paths = glob.glob(\"./paintings/*.jpg\")\n",
    "dataset_paths;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f83608",
   "metadata": {},
   "source": [
    "‚ùì **Display the image at index `53` of this dataset_paths (i.e the 54-th image)**\n",
    "\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "    Use the <code>PIL.Image.open</code> and <code>matplotlib.pyplot.imshow</code> functions.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e649f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T16:29:51.113503Z",
     "start_time": "2021-06-22T16:29:50.814346Z"
    },
    "scrolled": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "img_path_54 = dataset_paths[54]\n",
    "img_54 = Image.open(img_path_54)\n",
    "plt.imshow(img_54)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_54"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb5bbd",
   "metadata": {},
   "source": [
    "‚ùì **What is the shape of the image you displayed above `img_shape`?  How many dimensions `img_dim` does it have ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5fed60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:21:56.497908Z",
     "start_time": "2021-06-23T10:21:56.481566Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "plt.imread(img_path_54).shape, plt.imread(img_path_54).ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = plt.imread(img_path_54).shape\n",
    "img_dim = plt.imread(img_path_54).ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfa2f8f",
   "metadata": {},
   "source": [
    "‚ùì **What was in the image above?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c7d612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:21:58.052065Z",
     "start_time": "2021-06-23T10:21:58.048720Z"
    }
   },
   "outputs": [],
   "source": [
    "img_shape = img_shape\n",
    "img_dim = img_dim\n",
    "\n",
    "# Uncomment the correct answer\n",
    "\n",
    "#is_portrait = True\n",
    "is_portrait = False\n",
    "\n",
    "is_colored_image = True\n",
    "#is_colored_image = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c7af3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T16:29:52.470213Z",
     "start_time": "2021-06-22T16:29:52.460817Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'data_loading',\n",
    "    img_shape=img_shape,\n",
    "    img_dim=img_dim,\n",
    "    is_portrait=is_portrait,\n",
    "    is_colored_image=is_colored_image\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03c718",
   "metadata": {},
   "source": [
    "## 2. Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66adbb66",
   "metadata": {},
   "source": [
    "‚ùì **Store all images from the dataset folder in a list of numpy arrays called `dataset_images`**\n",
    "\n",
    "- It can take a while\n",
    "- If the dataset is too big to fit in memory, just take the first half (or quarter) of all pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde7713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:28:34.805289Z",
     "start_time": "2021-06-23T10:28:27.382300Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_images = [plt.imread(img_path) for img_path in dataset_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a649f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba549a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset_images[4])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a2716",
   "metadata": {},
   "source": [
    "### 2.1 Reshape, Resize, Rescale\n",
    "\n",
    "Let's simplify our dataset and convert it to a single numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c1af3",
   "metadata": {},
   "source": [
    "‚ùì **First, check if that all the images in the dataset have the same number of dimensions**.\n",
    "- What do you notice?\n",
    "- How do you explain it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7087ea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:28:44.316205Z",
     "start_time": "2021-06-23T10:28:44.310643Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "same_dim = [1 if x.ndim==3 else 0 for x in tqdm(dataset_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91931d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(same_dim)/len(same_dim)\n",
    "\n",
    "# We notice that only about 93% of the images have dimension 3, they are 3-colored images.\n",
    "# The others are black and white images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2b5fc",
   "metadata": {},
   "source": [
    "üëâ We convert for you all black & white images into 3-colored ones by duplicating the image on three channels, so as to have only 3D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9fc55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:28:47.187214Z",
     "start_time": "2021-06-23T10:28:46.380958Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_images = [x if x.ndim==3 else np.repeat(x[:,:,None], 3, axis=2) for x in tqdm(dataset_images)]\n",
    "set([x.ndim for x in dataset_images])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84865561",
   "metadata": {},
   "source": [
    "‚ùì **What about their shape now ?**\n",
    "- Do they all have the same width/heights ? If not:\n",
    "- Resize the images (120 pixels height and 100 pixels width) in the dataset, using `tensorflow.image.resize` function.\n",
    "- Now that they all have the same shape, store them as a numpy array `dataset_resized`.\n",
    "- This array should thus be of size $(n_{images}, 120, 100, 3)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39739658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:28:49.507681Z",
     "start_time": "2021-06-23T10:28:49.008011Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_images[27].shape, dataset_images[54].shape\n",
    "\n",
    "# No, they do not all have the same width/heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7374723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing\n",
    "\n",
    "dataset_resized = [tf.image.resize(im, (120, 100)).numpy() for im in dataset_images]\n",
    "\n",
    "dataset_resized = np.asarray(dataset_resized)\n",
    "dataset_resized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701f787",
   "metadata": {},
   "source": [
    "‚ùì **Rescale the data of each image between $0$ and $1$**\n",
    "- Save your resulting list as `dataset_scaled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c54d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_resized.min(), dataset_resized.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c7002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:28:50.891273Z",
     "start_time": "2021-06-23T10:28:50.782816Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# Rescaling\n",
    "\n",
    "dataset_scaled = dataset_resized/255.\n",
    "\n",
    "dataset_scaled.min(), dataset_scaled.max(), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdeeb0f",
   "metadata": {},
   "source": [
    "### 2.2 Create (X,y) sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe8c8f",
   "metadata": {},
   "source": [
    "üëâ Now, we'll add for you some **random noise** to our images to simulate noise (that our model will try to remove later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd79f84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:29:10.835518Z",
     "start_time": "2021-06-23T10:29:09.493359Z"
    }
   },
   "outputs": [],
   "source": [
    "NOISE_LEVEL = 0.2\n",
    "\n",
    "dataset_noisy = np.clip(\n",
    "    dataset_scaled + np.random.normal(\n",
    "        loc=0,\n",
    "        scale=NOISE_LEVEL,\n",
    "        size=dataset_scaled.shape\n",
    "    ).astype(np.float32),\n",
    "    0,\n",
    "    1\n",
    ")\n",
    "dataset_noisy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31c361",
   "metadata": {},
   "source": [
    "‚ùì **Plot a noisy image below to visualize the noise and compare it with the normal one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e70bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:29:55.333783Z",
     "start_time": "2021-06-23T10:29:55.096888Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "plt.imshow(dataset_noisy[54,:,:], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Noisy image');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807beb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:29:55.333783Z",
     "start_time": "2021-06-23T10:29:55.096888Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "plt.imshow(dataset_scaled[54,:,:], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Normal image');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d72d4f7",
   "metadata": {},
   "source": [
    "‚ùì **Create your `(X_train, Y_train)`, `(X_test, Y_test)` training set for your problem**\n",
    "\n",
    "- Remember you are trying to use \"noisy\" pictures in order to predict the \"normal\" ones.\n",
    "- Keeping about `20%` of randomly sampled data as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76718804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:07.250213Z",
     "start_time": "2021-06-23T10:30:07.064577Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8883c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset_noisy, dataset_scaled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25305b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:09.276772Z",
     "start_time": "2021-06-23T10:30:09.182183Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    \"preprocessing\",\n",
    "    X_train_shape = X_train.shape,\n",
    "    Y_train_shape = Y_train.shape,\n",
    "    X_std = X_train[:,:,:,0].std(),\n",
    "    Y_std = Y_train[:,:,:,0].std(),\n",
    "    first_image = Y_train[0]\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0de6c",
   "metadata": {},
   "source": [
    "## 3. Convolutional Neural Network\n",
    "\n",
    "A commonly used neural network architecture for image denoising is the __AutoEncoder__.\n",
    "\n",
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/autoencoder.png?raw=true'>\n",
    "\n",
    "Its goal is to learn a compact representation of your data to reconstruct them as precisely as possible.  \n",
    "The loss for such model must incentivize it to have __an output as close to the input as possible__.\n",
    "\n",
    "For this challenge, __you will only be asked to code the Encoder part of the network__, since building a Decoder leverages layers architectures you are not familiar with (yet)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ac7a1",
   "metadata": {},
   "source": [
    "üëâ Run this code below if you haven't managed to build your own (X,Y) training sets. This will load them as solution\n",
    "\n",
    "```python\n",
    "! curl https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_painting_solution.pickle > data_painting_solution.pickle\n",
    "\n",
    "import pickle\n",
    "with open(\"data_painting_solution.pickle\", \"rb\") as file:\n",
    "    (X_train, Y_train, X_test, Y_test) = pickle.load(file)\n",
    "    \n",
    "! rm data_painting_solution.pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! curl https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_painting_solution.pickle > data_painting_solution.pickle\n",
    "\n",
    "# import pickle\n",
    "# with open(\"data_painting_solution.pickle\", \"rb\") as file:\n",
    "#     (X_train_p, Y_train_p, X_test_p, Y_test_p) = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_p.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3760e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_p[:,:,:,0].std(), X_train[:,:,:,0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0453fe06",
   "metadata": {},
   "source": [
    "### 3.1 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea5abf",
   "metadata": {},
   "source": [
    "üëâ Run the cell below that defines the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a041216f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:19.889423Z",
     "start_time": "2021-06-23T10:30:19.881148Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa778c4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:21.897416Z",
     "start_time": "2021-06-23T10:30:21.771372Z"
    }
   },
   "outputs": [],
   "source": [
    "# We choose to compress images into a latent_dimension of size 6000\n",
    "latent_dimensions = 6000\n",
    "\n",
    "# We build a decoder that takes 1D-vectors of size 6000 to reconstruct images of shape (120,100,3)\n",
    "decoder = Sequential(name='decoder')\n",
    "decoder.add(layers.Reshape((30, 25, 8), input_dim=latent_dimensions))\n",
    "decoder.add(layers.Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "decoder.add(layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "decoder.add(layers.Conv2D(filters=3, kernel_size=3, padding=\"same\", activation=\"sigmoid\"))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6898a0",
   "metadata": {},
   "source": [
    "‚ùì **Now, build the `encoder` that plugs correctly with the decoder defined above**. Make sure that:\n",
    "- The output of your `encoder` is the same shape as the input of the `decoder`\n",
    "- Use a convolutional neural network architecture without transfer learning\n",
    "- Keep it simple\n",
    "- Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045f4ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:30.254803Z",
     "start_time": "2021-06-23T10:30:30.251255Z"
    }
   },
   "outputs": [],
   "source": [
    "# CODE HERE YOUR ENCODER ARCHITECTURE AND PRINT IT'S MODEL SUMMARY\n",
    "encoder = Sequential(name='encoder')\n",
    "\n",
    "encoder.add(layers.Conv2D(filters=32, kernel_size=3, input_shape=input_shape, activation='relu'))\n",
    "encoder.add(layers.MaxPooling2D(2))\n",
    "    \n",
    "encoder.add(layers.Conv2D(filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "encoder.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "encoder.add(layers.Conv2D(filters=16, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "encoder.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "encoder.add(layers.Flatten())\n",
    "encoder.add(layers.Dense(latent_dimensions, activation='tanh'))\n",
    "\n",
    "encoder.summary()\n",
    "#encoder = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a5b6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T09:32:05.702398Z",
     "start_time": "2021-06-22T09:32:05.696251Z"
    }
   },
   "source": [
    "üëâ **Test your encoder below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5222bca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:31.061011Z",
     "start_time": "2021-06-23T10:30:30.994105Z"
    }
   },
   "outputs": [],
   "source": [
    "# HERE WE BUILD THE AUTO-ENCODER (ENCODER + DECODER) FOR YOU. IT SHOULD PRINT A NICE SUMMARY\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "x = layers.Input(shape=(120, 100, 3))\n",
    "autoencoder = Model(x, decoder(encoder(x)), name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85758852",
   "metadata": {},
   "source": [
    "### 3.2 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0f3c1",
   "metadata": {},
   "source": [
    "‚ùì **Before training the autoencoder, evaluate your baseline score**\n",
    "- We will use the mean absolute error in this challenge\n",
    "- Compute the baseline score on your test set in the \"stupid\" case where you don't manage to de-noise anything at all.\n",
    "- Store the result under `score_baseline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54658fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_baseline = np.mean(X_test[:,:,:,0].std())\n",
    "score_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def7c160",
   "metadata": {},
   "source": [
    "‚ùì Now, **train your autoencoder**\n",
    "\n",
    "- Use an appropriate loss\n",
    "- Adapt the learning rate of your optimizer if convergence is too slow/fast\n",
    "- Make sure your model does not overfit with appropriate control techniques\n",
    "\n",
    "üí° You will not be judged by the computing power of your computer, you can reach decent performance in less than 5 minutes of training without GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ec508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:32.996335Z",
     "start_time": "2021-06-23T10:30:32.977099Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss=losses.MeanSquaredError(),\n",
    "                    metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "es = callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "\n",
    "autoencoder.fit(X_train, Y_train,\n",
    "          batch_size=32,\n",
    "          epochs=50,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es],\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ef73b",
   "metadata": {},
   "source": [
    "‚ùì **Plot your training and validation loss at each epoch using the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318110c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig = plt.gcf()\n",
    "    plt.plot(history.history['loss'], label = 'Train')\n",
    "    plt.plot(history.history['val_loss'], label = 'Validation')\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Run also this code to save figure as jpg in path below (it's your job to ensure it works)\n",
    "    plt.savefig(\"tests/history.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ee009",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(autoencoder.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c8d885",
   "metadata": {},
   "source": [
    "‚ùì **Evaluate your performances on test set**\n",
    "- Compute your de-noised test set `Y_pred` \n",
    "- Store your test score as `score_test`\n",
    "- Plot a de-noised image from your test set and compare it with the original and noisy one using the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13d748f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:33:23.147732Z",
     "start_time": "2021-06-23T10:33:22.679613Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "Y_pred = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0444c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test = autoencoder.evaluate(X_test, X_test)\n",
    "score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = autoencoder.evaluate(X_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60816a03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:34:10.656669Z",
     "start_time": "2021-06-23T10:34:10.159522Z"
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO CHECK YOUR RESULTS\n",
    "idx = 0\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(10,5))\n",
    "axs[0].imshow(Y_test[idx])\n",
    "axs[0].set_title(\"Clean image.\")\n",
    "\n",
    "axs[1].imshow(X_test[idx])\n",
    "axs[1].set_title(\"Noisy image.\")\n",
    "\n",
    "axs[2].imshow(Y_pred[idx])\n",
    "axs[2].set_title(\"Prediction.\")\n",
    "\n",
    "# Run this to save your results for correction\n",
    "plt.savefig('tests/image_denoised.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed16a58",
   "metadata": {},
   "source": [
    "üß™ **Send your results below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce318da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:33:23.944158Z",
     "start_time": "2021-06-23T10:33:23.936725Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"network\",\n",
    "    input_shape = list(encoder.input.shape),\n",
    "    output_shape = list(encoder.output.shape),\n",
    "    layer_names = [layer.name for layer in encoder.layers],\n",
    "    trainable_params = sum([tf.size(w_matrix).numpy() for w_matrix in encoder.trainable_variables]),\n",
    "    score_baseline = score_baseline,\n",
    "    score_test = score_test,\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a32db28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39eed5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "178px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
